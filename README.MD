# ğŸ™ï¸ AI-Powered Content Generation Pipeline

## ğŸš€ Overview
  
A personal project exploring AI agents for autonomous content creation. Built to experiment with how AI can coordinate multiple tools,language models, text to speech, image generation, and web search to complete multi-step creative tasks with minimal guidance.

## Demo

https://github.com/user-attachments/assets/8db854da-f108-4827-8248-54eecaf5a8db


## Reddit story audio demo
**Prompt:** `Tell a short halloween story`

https://github.com/user-attachments/assets/5b19c703-97da-40ab-8cb4-5c238306f54e

(Voice generated by Kokoro(local))

## Business psychology audio
**Prompt:** `Research the psyhoclogy of why most stores put the milk at the back of the store`

https://github.com/user-attachments/assets/2dfb8f62-8788-4b3a-aebb-86e7a8d9e8ed


## Podcast style
**Prompt:** `Discuss how crazy fast cheetahs are`

https://github.com/user-attachments/assets/224fa60b-ea89-47e5-8b70-499169305f6c


## Final video of the halloween story
https://github.com/user-attachments/assets/3486fc18-306f-4793-a4d1-4955eb174ebb



## What It Can Create

- **Reddit-style stories** with emotional arcs and hooks
- **Podcast conversations** between two speakers  
- **Research-based content** using real web searches tool for accuracy
- **Videos with synchronized visuals** that match the audio content (current only surpport AI-generate images)

---

## ğŸ› ï¸ Tech Stack

- **Language Models:** Claude / GPT-4 via OpenRouter  
- **AI voice:** ElevenLabs, Kokoro, FastAPI server  
- **Image Generation:** Google Nano Banana (Via Openrouter)
- **Web Research ** tool for the agent: Tavily 
- **Backend:** FastAPI + AWS S3 storage   

---

## ğŸ¯ Future Roadmap

- [ ] Improve image generation to support multiple images per section
- [ ] Add cinematic effects to videos (e.g., slow zoom, pan, etc.)
- [ ] Enable story regeneration with user provided improvement feedback

---

## ğŸ’­ What I Learned

- **Agent orchestration** â€“ How to design systems where AI autonomously decides which tools to use
- **Multi agents workflow** â€“ Breaking complex tasks into differnt agents resposibilities and orchestrate their collaboration
- **Tool integration** â€“ Making multiple AI services work together reliably
- **Prompt engineering** â€“ Crafting prompts that guide agent behavior across different content styles
- **System design** â€“ Building modular architectures that can easily support new features (different story types, different tts providers etc..), as well as robust system designs such as retry logic since LLM's response aren't always reliable.


## ğŸ“ License

MIT License
